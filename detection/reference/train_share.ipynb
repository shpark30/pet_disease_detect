{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3fd9e5",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ Ïù∏Ïûê ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde8581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "epochs=10  #default 300\n",
    "weights= 'yolov5s.pt'\n",
    "#evolve = Í∞ÄÏ§ëÏπò ÏßÑÌôî #default 300\n",
    "train_dir= '/home/appuser/animaldata_62_mu/input/train/Î∞±ÎÇ¥Ïû•/'\n",
    "class_num=2 #nc\n",
    "class_name= ['Î¨¥', 'Ïú†'] #names\n",
    "resume= False # help='resume most recent training'\n",
    "imgsz=640\n",
    "#noval=   help='disable AutoAnchor'\n",
    "#nosave=  help='resume most recent training'\n",
    "workers=8  #help='max dataloader workers (per RANK in DDP mode) #CPU ÏΩîÏñ¥  #Í∞ÑÎã®ÌïòÍ≤å ÏÑ§Î™ÖÌïòÎ©¥ Îç∞Ïù¥ÌÑ∞ Î°úÎìúÌï† Îïå Î™áÍ∞úÏùò ÌîÑÎ°úÏÑ∏Ïä§Î•º ÏÇ¨Ïö©Ìï†ÎûòÏöî? ÎùºÎäî ÌååÎùºÎØ∏ÌÑ∞ Ïù¥Îã§.\n",
    "#ÏúÑÏóê ÏÇ¨Ïù¥Ìä∏Îäî num_workersÎ•º Î™áÏúºÎ°úÌï¥Ïïº Ï¢ãÏùÑÏßÄÏóê ÎåÄÌïú ÌÜ†ÏùòÎ•º ÌïòÎäî Ìè¨Ïä§Ìä∏Ïù∏Îç∞ Ïã§ÌóòÏÉÅ Í∞ÄÏû• Ï¢ãÏïòÎçò Í≥µÏãùÏùÄ num_workers = 4 * num_of_gpus ÎùºÍ≥† ÌïúÎã§.\n",
    "freeze=[0] #ÎèôÍ≤∞ ÏóÜÏùå\n",
    "lr0 = 0.01 #default 0.01 # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "warmup_bias_lr = 0.1  # warmup initial bias lr\n",
    "momentum =  0.937  # SGD momentum/Adam beta1\n",
    "optimizer_type = 'SGD' #choices=['SGD', 'Adam', 'AdamW']\n",
    "weight_decay = 0.0005  # optimizer weight decay 5e-4\n",
    "lrf= 0.2  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "patience = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1562c0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK -1 RANK -1 WORLD_SIZE 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\n",
    "RANK = int(os.getenv('RANK', -1))\n",
    "WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))\n",
    "print(\"LOCAL_RANK\", LOCAL_RANK, \"RANK\", RANK, \"WORLD_SIZE\", WORLD_SIZE)\n",
    "last, best ='last.pt', 'best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e1cd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ca1ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device =  torch.device('cuda:0' if cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a3fb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def init_seeds(seed=0):\n",
    "    # Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    # cudnn seed 0 settings are slower and more reproducible, else faster and less reproducible\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    cudnn.benchmark, cudnn.deterministic = (False, True) if seed == 0 else (True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b08a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seeds(1 + RANK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2204f",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b54e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/appuser/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 üöÄ 2022-2-18 torch 1.10.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients\n",
      "\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "models = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=False,  classes=2) # create\n",
    "\n",
    "# models.yolo.Detect [80, [[10, 13, 16, 30, 33, 23], . . .  [128, 256, 512]] ---> [2, [[10, 13, 16, 30, 33, 23], . . .  [128, 256, 512]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c4ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze\n",
    "freeze_ = [f'model.{x}.' for x in (freeze if len(freeze) > 1 else range(freeze[0]))] \n",
    "for k, v in models.named_parameters():\n",
    "        v.requires_grad = True  # train all layers\n",
    "        if any(x in k for x in freeze_):\n",
    "            print(f'freezing {k}')\n",
    "            v.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1083a987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(models.stride.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size - Ìï¥Îãπ Î™®Îç∏Ïùò max strideÎäî 32Î°ú,resize Ïù¥ÎØ∏ÏßÄÍ∞Ä 32Ïùò Î∞∞ÏàòÏó¨Ïïº Ìï®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa783857",
   "metadata": {},
   "source": [
    "## optimizer, learning rate ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa143898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer parameter groups\n",
    "#pretrained =False\n",
    "import torch.nn as nn\n",
    "g0, g1, g2 = [], [], []  \n",
    "for v in models.modules():\n",
    "    if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):  # bias\n",
    "        g2.append(v.bias)\n",
    "    if isinstance(v, nn.BatchNorm2d):  # weight (no decay)\n",
    "        g0.append(v.weight)\n",
    "    elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):  # weight (with decay)\n",
    "        g1.append(v.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f2f5594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "from torch.optim import SGD, Adam, AdamW, lr_scheduler\n",
    "if optimizer_type == 'Adam':\n",
    "    optimizer = Adam(g0, lr=lr0, betas=(momentum, 0.999))  # adjust beta1 to momentum\n",
    "elif optimizer_type == 'AdamW':\n",
    "    optimizer = AdamW(g0, lr=lr0, betas=(momentum, 0.999))  # adjust beta1 to momentum\n",
    "else:\n",
    "    optimizer = SGD(g0, lr=lr0, momentum=momentum, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51e3a3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n"
     ]
    }
   ],
   "source": [
    "# optimizer parameter groupÏóê Í∞íÏùÑ Ïù¥ÎØ∏ ÎÑ£ÏùÄ Í≤ΩÏö∞ Ìï¥Îãπ ÏÖÄÏùÄ Ïò§Î•ò Î©îÏÑ∏ÏßÄÎ•º ÎùÑÏö∏ Ïàò ÏûàÏùå(some parameters appear in more than one parameter group)\n",
    "optimizer.add_param_group({'params': g1, 'weight_decay': weight_decay})  # add g1 with weight_decay\n",
    "optimizer.add_param_group({'params': g2})  # add g2 (biases)\n",
    "print(f\"{'optimizer:'} {type(optimizer).__name__} with parameter groups \"\n",
    "            f\"{len(g0)} weight (no decay), {len(g1)} weight, {len(g2)} bias\")\n",
    "del g0, g1, g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00d38b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0.937\n",
       "    nesterov: True\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0.937\n",
       "    nesterov: True\n",
       "    weight_decay: 0.0005\n",
       "\n",
       "Parameter Group 2\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0.937\n",
       "    nesterov: True\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aae32290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scheduler\n",
    "linear_lr = True\n",
    "if linear_lr:\n",
    "    lf = lambda x: (1 - x / (epochs - 1)) * (1.0 - lrf) + lrf  # linear\n",
    "else:\n",
    "    lf = one_cycle(1, lrf, epochs)  # cosine 1->hyp['lrf']\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)  # plot_lr_scheduler(optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91a86a51",
   "metadata": {},
   "source": [
    "list(map(lambda x: (1 - x / (epochs - 1)) * (1.0 - lrf) + lrf, range(10)))\n",
    "\"\"\"\n",
    "[1.0,\n",
    " 0.9111111111111112,\n",
    " 0.8222222222222222,\n",
    " 0.7333333333333334,\n",
    " 0.6444444444444445,\n",
    " 0.5555555555555556,\n",
    " 0.46666666666666673,\n",
    " 0.37777777777777777,\n",
    " 0.288888888888889,\n",
    " 0.2]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5545635",
   "metadata": {},
   "source": [
    "## ÏßÄÏàò Ïù¥Îèô ÌèâÍ∑† Ï†ÅÏö©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24396246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class ModelEMA:\n",
    "    \"\"\" Updated Exponential Moving Average (EMA) from https://github.com/rwightman/pytorch-image-models\n",
    "    Keeps a moving average of everything in the model state_dict (parameters and buffers)\n",
    "    For EMA details see https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, decay=0.9999, updates=0):\n",
    "        # Create EMA\n",
    "        self.ema = deepcopy(model.module if type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel) else model).eval()  # FP32 EMA\n",
    "        # if next(model.parameters()).device.type != 'cpu':\n",
    "        #     self.ema.half()  # FP16 EMA\n",
    "        self.updates = updates  # number of EMA updates\n",
    "        self.decay = lambda x: decay * (1 - math.exp(-x / 2000))  # decay exponential ramp (to help early epochs)\n",
    "        for p in self.ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def update(self, model):\n",
    "        # Update EMA parameters\n",
    "        with torch.no_grad():\n",
    "            self.updates += 1\n",
    "            d = self.decay(self.updates)\n",
    "\n",
    "            msd = de_parallel(model).state_dict()  # model state_dict\n",
    "            for k, v in self.ema.state_dict().items():\n",
    "                if v.dtype.is_floating_point:\n",
    "                    v *= d\n",
    "                    v += (1 - d) * msd[k].detach()\n",
    "\n",
    "    def update_attr(self, model, include=(), exclude=('process_group', 'reducer')):\n",
    "        # Update EMA attributes\n",
    "        copy_attr(self.ema, model, include, exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29f5a779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EMA\n",
    "ema = ModelEMA(models) if RANK in [-1, 0] else None\n",
    "#ÏßÄÏàò Ïù¥Îèô ÌèâÍ∑† (EMA)ÏùÄ Í∞ÄÏû• ÏµúÍ∑ºÏùò Îç∞Ïù¥ÌÑ∞ Ìè¨Ïù∏Ìä∏Ïóê Îçî ÌÅ∞ Í∞ÄÏ§ëÏπòÏôÄ Ï§ëÏöîÏÑ±ÏùÑ Î∂ÄÏó¨ÌïòÎäî Ïù¥Îèô ÌèâÍ∑† ( MA ) Ïú†ÌòïÏûÖÎãàÎã§. ÏßÄÏàò Ïù¥Îèô ÌèâÍ∑†ÏùÄ ÏßÄÏàò Í∞ÄÏ§ëÏπò Ïù¥Îèô ÌèâÍ∑† Ïù¥ÎùºÍ≥†ÎèÑ Ìï©ÎãàÎã§. ÏßÄÏàò Í∞ÄÏ§ë Ïù¥Îèô ÌèâÍ∑†ÏùÄ Ìï¥Îãπ Í∏∞Í∞ÑÏùò Î™®Îì† Í¥ÄÏ∏°ÏπòÏóê ÎèôÏùºÌïú Í∞ÄÏ§ëÏπòÎ•º Ï†ÅÏö©ÌïòÎäî Îã®Ïàú Ïù¥Îèô ÌèâÍ∑† ( SMA ) Î≥¥Îã§ ÏµúÍ∑º Í∞ÄÍ≤© Î≥ÄÎèôÏóê Îçî ÌÅ¨Í≤å Î∞òÏùëÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf81ca0",
   "metadata": {},
   "source": [
    "## DataParallel Ï†ÅÏö©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62b2f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.\n"
     ]
    }
   ],
   "source": [
    "# DP mode\n",
    "if cuda and RANK == -1 and torch.cuda.device_count() > 1: # True\n",
    "    print('WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\\n'\n",
    "                   'See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.')\n",
    "    model = torch.nn.DataParallel(models)\n",
    "#DataParallelÏùÄ Îã®Ïùº Î®∏Ïã†ÏóêÏÑúÎßå Í∞ÄÎä•, ÏÜçÎèÑÎèÑ ÎäêÎ¶º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc185742",
   "metadata": {},
   "source": [
    "## trainloader"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4df54915",
   "metadata": {},
   "source": [
    "<Îç∞Ïù¥ÌÑ∞ ÌååÏïÖ>\n",
    "\n",
    "0. sqlÎ¨∏ Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù\n",
    "1)Ï¥ù Îç∞Ïù¥ÌÑ∞ Ïàò : 300,000\n",
    "\n",
    "2) Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤¥Î•º ÎùºÎ≤®ÎßÅ ÌïòÏßÄ ÏïäÏùÄ Îç∞Ïù¥ÌÑ∞ Ïàò(JSON ÎÇ¥ Ï†ïÎ≥¥Î°ú ÌååÏïÖ) : 142,104\n",
    "select *\n",
    "from(\n",
    "select \n",
    "file_name, file_path,\n",
    "jsonb_path_query_first(file_cn::jsonb, '$.images.meta.width_height[0]' ) img_h, \n",
    "jsonb_path_query_first(file_cn::jsonb, '$.images.meta.width_height[1]' ) img_w, \n",
    "jsonb_path_query(file_cn::jsonb, '$.label.label_bbox[2]') bbox_h,\n",
    "jsonb_path_query(file_cn::jsonb, '$.label.label_bbox[3]') bbox_w\n",
    "from DT0000000425 ) z where    img_h != bbox_h and img_w != bbox_w -- 141,751\n",
    "\n",
    "\n",
    "1.ÏÇ¨Î°Ä img_h < bbox_h and img_w < bbox_w\n",
    "{\"images\":{\"meta\":{\"date_time\":\"2013-12-27 00:00:00\",\"gender\":1,\"medical_type\":1,\"file_name\":\"D11_951888f8-63a6-11ec-b317-0a7404972c70.jpg\",\"width_height\":[378,269],\"eye_position\":\"Ïò§Î•∏Ï™ΩÎàà\",\"image_resolution\":[0,0],\"device\":\"ÏïàÍµ¨Ï¥àÏùåÌåå\",\"age\":9,\"breed\":\"ÏöîÌÅ¨ÏÖî ÌÖåÎ¶¨Ïñ¥\"}},\"label\":{\"label_disease_nm\":\"Î∞±ÎÇ¥Ïû•\",\"label_bbox\":[0.0,0.0,800.0,600.0],\"label_filename\":\"crop_D11_951888f8-63a6-11ec-b317-0a7404972c70.jpg\",\"label_category_id\":1,\"label_disease_lv_3\":\"Î¨¥\",\"label_deleted\":0,\"label_path\":\"ÎùºÎ≤®ÎßÅÎç∞Ïù¥ÌÑ∞\\/ÏïàÍµ¨\\/Í∞ú\\/ÏïàÍµ¨\\/ÏïàÍµ¨Ï¥àÏùåÌåå\\/Î∞±ÎÇ¥Ïû•\\/Î¨¥\\/crop_D11_951888f8-63a6-11ec-b317-0a7404972c70.jpg\",\"label_disease_lv_1\":\"Î¨¥\",\"label_disease_lv_2\":\"Î¨¥\"}}\n",
    "\n",
    "ÏõêÏ≤úÏù¥ÎØ∏ÏßÄ : (378,269,3)\n",
    "ÎùºÎ≤®ÎßÅÏù¥ÎØ∏ÏßÄ : (400,400,3)\n",
    "\n",
    "2. ÏÇ¨Î°Ä img_h > bbox_h and img_w > bbox_w\n",
    "{\"images\":{\"meta\":{\"date_time\":\"2021-10-30 00:00:00\",\"gender\":1,\"medical_type\":1,\"file_name\":\"D11_9c59c2d5-63a6-11ec-b317-0a7404972c70.jpg\",\"width_height\":[383,382],\"eye_position\":\"ÏôºÏ™ΩÎàà\",\"image_resolution\":[300,300],\"device\":\"ÏïàÍµ¨Ï¥àÏùåÌåå\",\"age\":1,\"breed\":\"Ìë∏Îì§\"}},\"label\":{\"label_disease_nm\":\"Î∞±ÎÇ¥Ïû•\",\"label_bbox\":[0.0,0.0,374.0,283.0],\"label_filename\":\"crop_D11_9c59c2d5-63a6-11ec-b317-0a7404972c70.jpg\",\"label_category_id\":1,\"label_disease_lv_3\":\"Î¨¥\",\"label_deleted\":0,\"label_path\":\"ÎùºÎ≤®ÎßÅÎç∞Ïù¥ÌÑ∞\\/ÏïàÍµ¨\\/Í∞ú\\/ÏïàÍµ¨\\/ÏïàÍµ¨Ï¥àÏùåÌåå\\/Î∞±ÎÇ¥Ïû•\\/Î¨¥\\/crop_D11_9c59c2d5-63a6-11ec-b317-0a7404972c70.jpg\",\"label_disease_lv_1\":\"Î¨¥\",\"label_disease_lv_2\":\"Î¨¥\"}}\n",
    "\n",
    "ÏõêÏ≤úÏù¥ÎØ∏ÏßÄ : (374,283,3)\n",
    "ÎùºÎ≤®ÎßÅÏù¥ÎØ∏ÏßÄ : (400,400,3)\n",
    "\n",
    "3.ÏÇ¨Î°Ä  img_h > bbox_h and img_w > bbox_w\n",
    "{\"images\":{\"meta\":{\"date_time\":\"2018-11-19 00:00:00\",\"gender\":0,\"medical_type\":1,\"file_name\":\"D15_3d0d5fa0-60a5-11ec-8402-0a7404972c70.jpg\",\"width_height\":[381,337],\"eye_position\":\"Ïò§Î•∏Ï™ΩÎàà\",\"image_resolution\":[0,0],\"device\":\"ÏïàÍµ¨Ï¥àÏùåÌåå\",\"age\":12,\"breed\":\"Ìë∏Îì§\"}},\"label\":{\"label_disease_nm\":\"Î∞±ÎÇ¥Ïû•\",\"label_bbox\":[0.0,0.0,405.0,222.0],\"label_filename\":\"crop_D15_3d0d5fa0-60a5-11ec-8402-0a7404972c70.jpg\",\"label_category_id\":1,\"label_disease_lv_3\":\"Ïú†\",\"label_deleted\":0,\"label_path\":\"ÎùºÎ≤®ÎßÅÎç∞Ïù¥ÌÑ∞\\/ÏïàÍµ¨\\/Í∞ú\\/ÏïàÍµ¨\\/ÏïàÍµ¨Ï¥àÏùåÌåå\\/Î∞±ÎÇ¥Ïû•\\/Ïú†\\/crop_D15_3d0d5fa0-60a5-11ec-8402-0a7404972c70.jpg\",\"label_disease_lv_1\":\"Ïú†\",\"label_disease_lv_2\":\"Ïú†\"}}\n",
    "\n",
    "ÏõêÏ≤úÏù¥ÎØ∏ÏßÄ : (405,222,3)\n",
    "ÎùºÎ≤®ÎßÅÏù¥ÎØ∏ÏßÄ : (400,400,3)\n",
    "\n",
    "4. ÏßÑÎã® Í≤∞Í≥º\n",
    "JSON ÎÇ¥ Ï¢åÌëú Í¥ÄÎ†®Îêú ÎùºÎ≤®ÎßÅ bbox Î∞è Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ Ï†ïÎ≥¥Î•º ÎØøÍ∏∞ Ïñ¥Î†§ÏõÄ.\n",
    "ÏõêÏ≤ú Ïù¥ÎØ∏ÏßÄÎäî Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Í∞Ä Ï†úÍ∞ÅÍ∞ÅÏûÑ\n",
    "=> ÎùºÎ≤®ÎßÅ Ïù¥ÎØ∏ÏßÄ ÎåÄÏÉÅÏúºÎ°ú, Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º bbox ÌÅ¨Í∏∞Î°ú Ïû°Í≥† classification ÏùòÎØ∏Î•º Îã¥ÏùÄ object detectionÏúºÎ°ú ÏßÑÌñâÌïòÎ©¥ Ï¢ãÏùÑ ÎìØÌï®."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c9addd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/appuser/animaldata_62_mu/input'\n",
    "disease_code = 'Î∞±ÎÇ¥Ïû•_Ï¥àÏùåÌåå'\n",
    "split_ratio = 0.2\n",
    "img_resize = 640\n",
    "mode = \"train\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89c6abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset.py\"\"\"\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, dataloader, distributed # #Î∞∞ÏπòÏóê ÎåÄÌï¥ÏÑú Î∞òÎ≥µÌïòÍ∏∞ Ìé∏Î¶¨ÌïòÍ≤å Ìï¥Ï§çÎãàÎã§.\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.image as img\n",
    "import json\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "\n",
    "class PETDataset_eye(Dataset): \n",
    "    \n",
    "    def __init__(self, root,disease_code ,split_ratio, mode, img_resize) : # file_list # imgsz, stride=int(stride)\n",
    "        self.root = root\n",
    "        self.disease_code = disease_code\n",
    "        self.mode = mode\n",
    "        self.split_ratio = split_ratio        \n",
    "        self.dir = {\"train\": self.root + '/' + \"train\" + '/' + self.disease_code,\n",
    "                    \"test\": self.root + '/' + \"test\" + '/' + self.disease_code}\n",
    "        self.file_list = []\n",
    "        self.img_resize= img_resize\n",
    "                \n",
    "        if self.mode == \"train\" : \n",
    "            train_Î¨¥_images = [f\"{self.dir['train']}/Î¨¥/\" + f for f in os.listdir(f\"{self.dir['train']}/Î¨¥\") if (f[-3:]==\"jpg\")]\n",
    "            train_Ïú†_images = [f\"{self.dir['train']}/Ïú†/\" + f for f in os.listdir(f\"{self.dir['train']}/Ïú†\") if (f[-3:]==\"jpg\")]\n",
    "            self.file_list = train_Î¨¥_images[:int(len(train_Î¨¥_images) * (1 - self.split_ratio))] + \\\n",
    "                                train_Ïú†_images[:int(len(train_Ïú†_images) * (1 - self.split_ratio))]\n",
    "            \n",
    "\n",
    "        elif self.mode == \"valid\" : \n",
    "            train_Î¨¥_images = [f\"{self.dir['train']}/Î¨¥/\" + f for f in os.listdir(f\"{self.dir['train']}/Î¨¥\") if (f[-3:]==\"jpg\")]\n",
    "            train_Ïú†_images = [f\"{self.dir['train']}/Ïú†/\" + f for f in os.listdir(f\"{self.dir['train']}/Ïú†\") if (f[-3:]==\"jpg\")]\n",
    "            self.file_list = train_Î¨¥_images[int(len(train_Î¨¥_images) * (1 - self.split_ratio)):] + \\\n",
    "                              train_Ïú†_images[int(len(train_Ïú†_images) * (1 - self.split_ratio)):]\n",
    "    \n",
    "        else : #mode = \"test\"\n",
    "            test_Î¨¥_images = [f\"{self.dir['test']}/Î¨¥/\" + f for f in os.listdir(f\"{self.dir['test']}/Î¨¥\") if (f[-3:]==\"jpg\")]\n",
    "            test_Ïú†_images = [f\"{self.dir['test']}/Ïú†/\" + f for f in os.listdir(f\"{self.dir['test']}/Ïú†\") if (f[-3:]==\"jpg\")]\n",
    "            self.file_list = test_Î¨¥_images + test_Ïú†_images           \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index): # model input, target for loss from file_list\n",
    "        img_path = self.file_list[index]\n",
    "        img = torch.from_numpy(self.resize_img(img_path))\n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "        json_path = os.path.join(img_path.replace(\".jpg\", \".json\"))    \n",
    "        with open(json_path) as f :\n",
    "            anno=json.load(f)\n",
    "        anno_label = anno['label']\n",
    "        label = [0,0,self.img_resize,self.img_resize]  #XYXY\n",
    "        if anno['label']['label_disease_nm'] != \"Î∞±ÎÇ¥Ïû•\" :\n",
    "            assert true, f\"ÏûòÎ™ªÎêú Îç∞Ïù¥ÌÑ∞ {anno['label']['label_disease_nm']} ÏßàÌôòÏù¥ Îì§Ïñ¥ÏôîÏäµÎãàÎã§.\"\n",
    "        if anno['label']['label_disease_lv_3'] == \"Î¨¥\" : \n",
    "            label.append(0)\n",
    "        elif anno['label']['label_disease_lv_3'] == \"Ïú†\" : \n",
    "            label.append(1)\n",
    "        else :\n",
    "            assert true, \"anno['label']['label_disease_lv_3'] Ïù¥ ÏûòÎ™ªÎêòÏóàÏäµÎãàÎã§.\"\n",
    "        \n",
    "        return {'input': img, 'target': torch.Tensor(label)} # ÌïòÎÇò Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌïú Ï†ïÏùò\n",
    "    \n",
    "    def resize_img(self, image_path) :   # stride Ï∂îÍ∞ÄÌïòÍ∏∞ Í∑ºÎç∞ Î≠ò Ï∂îÍ∞ÄÌï¥ÏïºÌï†Î†§ÎÇò.\n",
    "        im = cv2.imread(image_path)  # BGR\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        h0, w0 = im.shape[:2]\n",
    "        r = self.img_resize / max(h0, w0)  # ratio\n",
    "        if r != 1:  # if sizes are not equal\n",
    "            im_2 = cv2.resize(im,(int(w0 * r), int(h0 * r)),\n",
    "                interpolation=cv2.INTER_LINEAR if r > 1 else cv2.INTER_AREA)\n",
    "        return im_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b694d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ (400,400,3)Í∞Ä ÏïÑÎãå Îç∞Ïù¥ÌÑ∞ Î™©Î°ù\n",
    "pet_for_wh = PETDataset_eye(root,disease_code,split_ratio, \"train\", img_resize)\n",
    "for image_path in pet_for_wh.file_list :\n",
    "    im = cv2.imread(image_path) \n",
    "    h0, w0 = im.shape[:2]\n",
    "    #print(image_path, h0, w0)\n",
    "    if h0 != 400 or w0 != 400 :\n",
    "        print(\"wrong\", image_path, h0,w0)  # ÏóÜÏùå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "078987c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ (400,400,3)Í∞Ä ÏïÑÎãå Îç∞Ïù¥ÌÑ∞ Î™©Î°ù\n",
    "pet_for_wh_2 = PETDataset_eye(root,disease_code,split_ratio, \"test\", img_resize)\n",
    "for image_path in pet_for_wh_2.file_list :\n",
    "    im = cv2.imread(image_path) \n",
    "    h0, w0 = im.shape[:2]\n",
    "    #print(image_path, h0, w0)\n",
    "    if h0 != 400 or w0 != 400 :\n",
    "        print(\"wrong\", image_path, h0,w0) #ÏóÜÏùå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45a012a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': tensor([[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 0]]], dtype=torch.uint8),\n",
       " 'target': tensor([  0.,   0., 640., 640.,   0.])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet = PETDataset_eye(root,disease_code,split_ratio, mode, img_resize)\n",
    "pet.__len__()\n",
    "pet.file_list[0]\n",
    "pet[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34613183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def torch_distributed_zero_first(local_rank: int):\n",
    "    \"\"\"\n",
    "    Decorator to make all processes in distributed training wait for each local_master to do something.\n",
    "    \"\"\"\n",
    "    if local_rank not in [-1, 0]:\n",
    "        dist.barrier(device_ids=[local_rank])\n",
    "    yield\n",
    "    if local_rank == 0:\n",
    "        dist.barrier(device_ids=[0])\n",
    "        \n",
    "def create_dataloader(path, imgsz, batch_size, mode, rank=-1, workers=8, shuffle=False):\n",
    "    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP\n",
    "#        dataset = LoadImagesAndLabels(path, imgsz, batch_size, stride=int(stride), pad=pad)\n",
    "#             0.path Í∞Ä Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏\n",
    "#             1. cache ÏùÑ load Ìï¥ÏÑú Ïù¥ÎØ∏ÏßÄ Ïàò found, missing, empty, corrupt, total ÏùΩÏñ¥Ïò§Îäî ÎìØÌï® \n",
    "#             2.ÎùºÎ≤® ÏßÄÏ†ïÌïú ÎùºÎ≤®Îßå ÏùΩÏñ¥Ïò§Îäî ÎìØÌï®\n",
    "#             3. Îπ†Î•∏ ÌïôÏäµÏùÑ ÏúÑÌï¥ Ïù¥ÎØ∏ÏßÄÎ•º cache Ìï®.\n",
    "        dataset = PETDataset_eye(root,disease_code,split_ratio, mode, img_resize)\n",
    "        \n",
    "    batch_size = min(batch_size, len(dataset))\n",
    "    nd = torch.cuda.device_count()  # number of CUDA devices\n",
    "    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers\n",
    "    #os.cpu_count() =16\n",
    "    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "    print(\"batch_size\", batch_size,\"number of CUDA devices\", nd, \"number of workers\", nw )\n",
    "    \n",
    "    return InfiniteDataLoader(dataset, #Dataloader ÎèÑ Í∞ÄÎä•\n",
    "                  batch_size=batch_size,\n",
    "                  shuffle=shuffle and sampler is None,\n",
    "                  num_workers=nw,\n",
    "                  sampler=sampler,\n",
    "                  pin_memory=True,\n",
    "                  collate_fn=None), dataset\n",
    "\n",
    "class InfiniteDataLoader(dataloader.DataLoader):\n",
    "    \"\"\" Dataloader that reuses workers\n",
    "    Uses same syntax as vanilla DataLoader\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        object.__setattr__(self, 'batch_sampler', _RepeatSampler(self.batch_sampler))\n",
    "        self.iterator = super().__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler.sampler)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield next(self.iterator) \n",
    "            \n",
    "class _RepeatSampler:\n",
    "    \"\"\" Sampler that repeats forever\n",
    "    Args:\n",
    "        sampler (Sampler)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sampler):\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield from iter(self.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64321222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 16 number of CUDA devices 2 number of workers 8\n",
      "number of batches 688\n"
     ]
    }
   ],
   "source": [
    "# Trainloader\n",
    "train_loader, dataset = create_dataloader(train_dir, imgsz, batch_size // WORLD_SIZE, mode=\"train\",  rank=LOCAL_RANK, workers=workers, shuffle=True)\n",
    "#mlc = int(np.concatenate(dataset.labels, 0)[:, 0].max())  # max label class\n",
    "nb = len(train_loader)  # number of batches\n",
    "print( \"number of batches\", nb ) ##print(\"max label class\", mlc, \"number of batches\", nb )\n",
    "# assert mlc < nc, f'Label class {mlc} exceeds nc={nc} in {data}. Possible class labels are 0-{nc - 1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ffc4759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 16 number of CUDA devices 2 number of workers 8\n"
     ]
    }
   ],
   "source": [
    "# Validloader\n",
    "if RANK in [-1, 0]:\n",
    "    val_loader = create_dataloader(train_dir, imgsz, batch_size // WORLD_SIZE, mode=\"valid\",  rank=LOCAL_RANK, workers=workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69856303",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch, best_fitness = 0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.DataParallel(models) ÏÇ¨Ïö©Ïãú \"model.module\", dataparallel ÏÇ¨Ïö©ÏïàÌï†Ïãú \"model.model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907e0d4",
   "metadata": {},
   "source": [
    "## ÌõàÎ†®(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b2056b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    # YOLOv5 simple early stopper\n",
    "    def __init__(self, patience=30):\n",
    "        self.best_fitness = 0.0  # i.e. mAP\n",
    "        self.best_epoch = 0\n",
    "        self.patience = patience or float('inf')  # epochs to wait after fitness stops improving to stop\n",
    "        self.possible_stop = False  # possible stop may occur next epoch\n",
    "\n",
    "    def __call__(self, epoch, fitness):\n",
    "        if fitness >= self.best_fitness:  # >= 0 to allow for early zero-fitness stage of training\n",
    "            self.best_epoch = epoch\n",
    "            self.best_fitness = fitness\n",
    "        delta = epoch - self.best_epoch  # epochs without improvement\n",
    "        self.possible_stop = delta >= (self.patience - 1)  # possible stop may occur next epoch\n",
    "        stop = delta >= self.patience  # stop training if patience exceeded\n",
    "        if stop:\n",
    "            LOGGER.info(f'Stopping training early as no improvement observed in last {self.patience} epochs. '\n",
    "                        f'Best results observed at epoch {self.best_epoch}, best model saved as best.pt.\\n'\n",
    "                        f'To update EarlyStopping(patience={self.patience}) pass a new patience value, '\n",
    "                        f'i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.')\n",
    "        return stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbe2b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sizes train 640 ,  val 640\n",
      "Using 8 dataloader workers\n",
      "Starting training for 10 epochs...\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "import time\n",
    "from torch.cuda import amp\n",
    "t0 = time.time()\n",
    "nw = max(round(3.0  * nb), 1000)  # number of warmup iterations, max(3 epochs, 1k iterations)\n",
    "last_opt_step = -1\n",
    "maps = np.zeros(class_num)  # mAP per class\n",
    "results = (0, 0, 0, 0, 0, 0, 0)  # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)\n",
    "scheduler.last_epoch = start_epoch - 1  # do not move\n",
    "scaler = amp.GradScaler(enabled=cuda)\n",
    "stopper = EarlyStopping(patience=patience)\n",
    "print(f'Image sizes train {imgsz} ,  val {imgsz}\\n'\n",
    "            f'Using {train_loader.num_workers * WORLD_SIZE} dataloader workers\\n'\n",
    "            f'Starting training for {epochs} epochs...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf757f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ac60e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8456002906976745\n",
      "0.8456002906976745\n",
      "0.8456002906976745\n"
     ]
    }
   ],
   "source": [
    "for j, x in enumerate(optimizer.param_groups):\n",
    "    if 'momentum' in x:\n",
    "        print(x['momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49ddb1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/688 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/688 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "nbs = 64  # nominal batch size\n",
    "#for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n",
    "for epoch in range(start_epoch, 1):\n",
    "    model.train()\n",
    "    mloss = torch.zeros(3, device=device)  # mean losses\n",
    "    if RANK != -1:\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "    pbar = enumerate(train_loader)\n",
    "    print(('\\n' + '%10s' * 7) % ('Epoch', 'gpu_mem', 'box', 'obj', 'cls', 'labels', 'img_size'))\n",
    "    if RANK in [-1, 0]:\n",
    "        pbar = tqdm(pbar, total=nb, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')  # progress bar\n",
    "    optimizer.zero_grad()\n",
    "    for i, value in enumerate(train_loader):  # batch -------------------------------------------------------------\n",
    "        ni = i + nb * epoch  # number integrated batches (since train start)\n",
    "        #imgs = imgs.to(device, non_blocking=True).float() / 255  # uint8 to float32, 0-255 to 0.0-1.0\n",
    "        imgs= value[\"input\"]\n",
    "        # Warmup\n",
    "        if ni <= nw:\n",
    "            xi = [0, nw]  # x interp\n",
    "            # compute_loss.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n",
    "            accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n",
    "            for j, x in enumerate(optimizer.param_groups):\n",
    "                # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
    "                x['lr'] = np.interp(ni, xi, [warmup_bias_lr if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
    "                if 'momentum' in x:\n",
    "                    x['momentum'] = np.interp(ni, xi, [ 0.8, 0.937])\n",
    "        \"\"\"Ïó¨Í∏∞ÍπåÏßÄ ÏßÑÌñâÌï®\"\"\"\n",
    "\n",
    "        # Forward\n",
    "        with amp.autocast(enabled=cuda):\n",
    "            pred = model(imgs)  # forward\n",
    "            loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size \n",
    "            if RANK != -1:\n",
    "                loss *= WORLD_SIZE  # gradient averaged between devices in DDP mode\n",
    "            if opt.quad:\n",
    "                loss *= 4.\n",
    "\n",
    "        # Backward\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Optimize\n",
    "        if ni - last_opt_step >= accumulate:\n",
    "            scaler.step(optimizer)  # optimizer.step\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            if ema:\n",
    "                ema.update(model)\n",
    "            last_opt_step = ni                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfda4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7923cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2bce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55e71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "938004d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataParallel' object has no attribute 'hyp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-712c98b0938c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# init loss class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-5068943991f0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, autobalance)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_obj_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m  \u001b[0;31m# get model device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyp\u001b[0m  \u001b[0;31m# hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Define criteria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'hyp'"
     ]
    }
   ],
   "source": [
    "compute_loss = ComputeLoss(model)  # init loss class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a391c65",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoShape' object has no attribute 'hyp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b2fa0f7a217e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoShape' object has no attribute 'hyp'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09a7d97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('module',\n",
       "               AutoShape(\n",
       "                 (model): Model(\n",
       "                   (model): Sequential(\n",
       "                     (0): Conv(\n",
       "                       (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "                       (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (1): Conv(\n",
       "                       (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (2): C3(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv3): Conv(\n",
       "                         (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): Sequential(\n",
       "                         (0): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                     (3): Conv(\n",
       "                       (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (4): C3(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv3): Conv(\n",
       "                         (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): Sequential(\n",
       "                         (0): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                         (1): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                     (5): Conv(\n",
       "                       (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (6): C3(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv3): Conv(\n",
       "                         (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): Sequential(\n",
       "                         (0): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                         (1): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                         (2): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                     (7): Conv(\n",
       "                       (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (8): C3(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv3): Conv(\n",
       "                         (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): Sequential(\n",
       "                         (0): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                     (9): SPPF(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "                     )\n",
       "                     (10): Conv(\n",
       "                       (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (11): Upsample(scale_factor=2.0, mode=nearest)\n",
       "                     (12): Concat()\n",
       "                     (13): C3(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv3): Conv(\n",
       "                         (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): Sequential(\n",
       "                         (0): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                     (14): Conv(\n",
       "                       (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (15): Upsample(scale_factor=2.0, mode=nearest)\n",
       "                     (16): Concat()\n",
       "                     (17): C3(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv3): Conv(\n",
       "                         (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): Sequential(\n",
       "                         (0): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                     (18): Conv(\n",
       "                       (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (19): Concat()\n",
       "                     (20): C3(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv3): Conv(\n",
       "                         (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): Sequential(\n",
       "                         (0): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                     (21): Conv(\n",
       "                       (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (22): Concat()\n",
       "                     (23): C3(\n",
       "                       (cv1): Conv(\n",
       "                         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv2): Conv(\n",
       "                         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (cv3): Conv(\n",
       "                         (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                         (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                         (act): SiLU(inplace=True)\n",
       "                       )\n",
       "                       (m): Sequential(\n",
       "                         (0): Bottleneck(\n",
       "                           (cv1): Conv(\n",
       "                             (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                           (cv2): Conv(\n",
       "                             (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                             (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                             (act): SiLU(inplace=True)\n",
       "                           )\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                     (24): Detect(\n",
       "                       (m): ModuleList(\n",
       "                         (0): Conv2d(128, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "                         (1): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "                         (2): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                 )\n",
       "               ))]),\n",
       " 'dim': 0,\n",
       " 'device_ids': [0, 1],\n",
       " 'output_device': 0,\n",
       " 'src_device_obj': device(type='cuda', index=0)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d3c7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeLoss:\n",
    "    # Compute losses\n",
    "    def __init__(self, model, autobalance=False):\n",
    "        self.sort_obj_iou = False\n",
    "        device = next(model.parameters()).device  # get model device\n",
    "        h = model.hyp  # hyperparameters\n",
    "\n",
    "        # Define criteria\n",
    "        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))\n",
    "        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))\n",
    "\n",
    "        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3\n",
    "        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets\n",
    "\n",
    "        # Focal loss\n",
    "        g = h['fl_gamma']  # focal loss gamma\n",
    "        if g > 0:\n",
    "            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)\n",
    "\n",
    "        det = de_parallel(model).model[-1]  # Detect() module\n",
    "        self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, 0.02])  # P3-P7\n",
    "        self.ssi = list(det.stride).index(16) if autobalance else 0  # stride 16 index\n",
    "        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance\n",
    "        for k in 'na', 'nc', 'nl', 'anchors':\n",
    "            setattr(self, k, getattr(det, k))\n",
    "\n",
    "    def __call__(self, p, targets):  # predictions, targets, model\n",
    "        device = targets.device\n",
    "        lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)\n",
    "        tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets\n",
    "\n",
    "        # Losses\n",
    "        for i, pi in enumerate(p):  # layer index, layer predictions\n",
    "            b, a, gj, gi = indices[i]  # image, anchor, gridy, gridx\n",
    "            tobj = torch.zeros_like(pi[..., 0], device=device)  # target obj\n",
    "\n",
    "            n = b.shape[0]  # number of targets\n",
    "            if n:\n",
    "                ps = pi[b, a, gj, gi]  # prediction subset corresponding to targets\n",
    "\n",
    "                # Regression\n",
    "                pxy = ps[:, :2].sigmoid() * 2 - 0.5\n",
    "                pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]\n",
    "                pbox = torch.cat((pxy, pwh), 1)  # predicted box\n",
    "                iou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  # iou(prediction, target)\n",
    "                lbox += (1.0 - iou).mean()  # iou loss\n",
    "\n",
    "                # Objectness\n",
    "                score_iou = iou.detach().clamp(0).type(tobj.dtype)\n",
    "                if self.sort_obj_iou:\n",
    "                    sort_id = torch.argsort(score_iou)\n",
    "                    b, a, gj, gi, score_iou = b[sort_id], a[sort_id], gj[sort_id], gi[sort_id], score_iou[sort_id]\n",
    "                tobj[b, a, gj, gi] = (1.0 - self.gr) + self.gr * score_iou  # iou ratio\n",
    "\n",
    "                # Classification\n",
    "                if self.nc > 1:  # cls loss (only if multiple classes)\n",
    "                    t = torch.full_like(ps[:, 5:], self.cn, device=device)  # targets\n",
    "                    t[range(n), tcls[i]] = self.cp\n",
    "                    lcls += self.BCEcls(ps[:, 5:], t)  # BCE\n",
    "\n",
    "                # Append targets to text file\n",
    "                # with open('targets.txt', 'a') as file:\n",
    "                #     [file.write('%11.5g ' * 4 % tuple(x) + '\\n') for x in torch.cat((txy[i], twh[i]), 1)]\n",
    "\n",
    "            obji = self.BCEobj(pi[..., 4], tobj)\n",
    "            lobj += obji * self.balance[i]  # obj loss\n",
    "            if self.autobalance:\n",
    "                self.balance[i] = self.balance[i] * 0.9999 + 0.0001 / obji.detach().item()\n",
    "\n",
    "        if self.autobalance:\n",
    "            self.balance = [x / self.balance[self.ssi] for x in self.balance]\n",
    "        lbox *= self.hyp['box']\n",
    "        lobj *= self.hyp['obj']\n",
    "        lcls *= self.hyp['cls']\n",
    "        bs = tobj.shape[0]  # batch size\n",
    "\n",
    "        return (lbox + lobj + lcls) * bs, torch.cat((lbox, lobj, lcls)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6011548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739cb377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb6c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db046e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14aa790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e33abbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('model',\n",
       "               Model(\n",
       "                 (model): Sequential(\n",
       "                   (0): Conv(\n",
       "                     (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "                     (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (1): Conv(\n",
       "                     (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                     (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (2): C3(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv3): Conv(\n",
       "                       (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): Sequential(\n",
       "                       (0): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                   (3): Conv(\n",
       "                     (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                     (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (4): C3(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv3): Conv(\n",
       "                       (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): Sequential(\n",
       "                       (0): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                       (1): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                   (5): Conv(\n",
       "                     (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                     (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (6): C3(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv3): Conv(\n",
       "                       (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): Sequential(\n",
       "                       (0): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                       (1): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                       (2): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                   (7): Conv(\n",
       "                     (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                     (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (8): C3(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv3): Conv(\n",
       "                       (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): Sequential(\n",
       "                       (0): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                   (9): SPPF(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "                   )\n",
       "                   (10): Conv(\n",
       "                     (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                     (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (11): Upsample(scale_factor=2.0, mode=nearest)\n",
       "                   (12): Concat()\n",
       "                   (13): C3(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv3): Conv(\n",
       "                       (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): Sequential(\n",
       "                       (0): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                   (14): Conv(\n",
       "                     (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                     (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (15): Upsample(scale_factor=2.0, mode=nearest)\n",
       "                   (16): Concat()\n",
       "                   (17): C3(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv3): Conv(\n",
       "                       (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): Sequential(\n",
       "                       (0): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                   (18): Conv(\n",
       "                     (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                     (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (19): Concat()\n",
       "                   (20): C3(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv3): Conv(\n",
       "                       (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): Sequential(\n",
       "                       (0): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                   (21): Conv(\n",
       "                     (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                     (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                     (act): SiLU(inplace=True)\n",
       "                   )\n",
       "                   (22): Concat()\n",
       "                   (23): C3(\n",
       "                     (cv1): Conv(\n",
       "                       (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv2): Conv(\n",
       "                       (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (cv3): Conv(\n",
       "                       (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                       (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                       (act): SiLU(inplace=True)\n",
       "                     )\n",
       "                     (m): Sequential(\n",
       "                       (0): Bottleneck(\n",
       "                         (cv1): Conv(\n",
       "                           (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                         (cv2): Conv(\n",
       "                           (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                           (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                           (act): SiLU(inplace=True)\n",
       "                         )\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                   (24): Detect(\n",
       "                     (m): ModuleList(\n",
       "                       (0): Conv2d(128, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "                       (1): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "                       (2): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "                     )\n",
       "                   )\n",
       "                 )\n",
       "               ))]),\n",
       " 'yaml': {'nc': 2,\n",
       "  'depth_multiple': 0.33,\n",
       "  'width_multiple': 0.5,\n",
       "  'anchors': [[10, 13, 16, 30, 33, 23],\n",
       "   [30, 61, 62, 45, 59, 119],\n",
       "   [116, 90, 156, 198, 373, 326]],\n",
       "  'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]],\n",
       "   [-1, 1, 'Conv', [128, 3, 2]],\n",
       "   [-1, 3, 'C3', [128]],\n",
       "   [-1, 1, 'Conv', [256, 3, 2]],\n",
       "   [-1, 6, 'C3', [256]],\n",
       "   [-1, 1, 'Conv', [512, 3, 2]],\n",
       "   [-1, 9, 'C3', [512]],\n",
       "   [-1, 1, 'Conv', [1024, 3, 2]],\n",
       "   [-1, 3, 'C3', [1024]],\n",
       "   [-1, 1, 'SPPF', [1024, 5]]],\n",
       "  'head': [[-1, 1, 'Conv', [512, 1, 1]],\n",
       "   [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']],\n",
       "   [[-1, 6], 1, 'Concat', [1]],\n",
       "   [-1, 3, 'C3', [512, False]],\n",
       "   [-1, 1, 'Conv', [256, 1, 1]],\n",
       "   [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']],\n",
       "   [[-1, 4], 1, 'Concat', [1]],\n",
       "   [-1, 3, 'C3', [256, False]],\n",
       "   [-1, 1, 'Conv', [256, 3, 2]],\n",
       "   [[-1, 14], 1, 'Concat', [1]],\n",
       "   [-1, 3, 'C3', [512, False]],\n",
       "   [-1, 1, 'Conv', [512, 3, 2]],\n",
       "   [[-1, 10], 1, 'Concat', [1]],\n",
       "   [-1, 3, 'C3', [1024, False]],\n",
       "   [[17, 20, 23], 1, 'Detect', ['nc', 'anchors']]],\n",
       "  'ch': 3},\n",
       " 'names': ['0', '1'],\n",
       " 'stride': tensor([ 8., 16., 32.]),\n",
       " 'dmb': False,\n",
       " 'pt': True}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.__dict__ #Ïò§,,, Ïä§Ïä§Î°ú Ïù¥ Ìï®Ïàò Ïç®Î®πÏñ¥Î≥ºÍπå Îñ†Ïò¨Î†∏Ïñ¥><\n",
    "# class_weightsÎ•º yamlÏóê ÎÑ£ÏúºÎ©¥ ÏûëÎèôÌï† Ïàò ÏûàÏùÑÏßÄÎèÑ..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a2dd9749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.yaml[\"nc\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
